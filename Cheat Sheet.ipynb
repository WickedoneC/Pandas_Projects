{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding New Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new 'num_lines' column that has a count of each line in linename\n",
    "df['num_lines'] = df['linename'].map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data type of the 'date' column to a date\n",
    "# Add a new column 'day_of_week' that represents the day of the week \n",
    "# Group the data by day of week and plot the sum of the numeric columns\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "df['day_of_week'] = df['date'].dt.dayofweek\n",
    "\n",
    "grouped = df.groupby('day_of_week').sum()\n",
    "grouped.plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this dictionary to create a new column \n",
    "weekend_map = {0:False, 1:False, 2:False, 3:False, 4:False, 5:True, 6:True}\n",
    "\n",
    "# Add a new column 'is_weekend' that maps the 'day_of_week' column using weekend_map\n",
    "grouped['is_weekend'] = grouped['day_of_week'].map(weekend_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename all the columns to lower case\n",
    "df.columns = [col.lower() for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(col_name):\n",
    "    # clean the column name in any way you want to. Hint: think back to str methods \n",
    "    cleaned = col_name.strip()\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the above function to clean the column names\n",
    "df.columns = [clean(col) for col in df.columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric statistics\n",
    "df['col_name'].[]\n",
    "[] = [mean, quantile, median, mode, count, std, var, sum, cumsum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical statistics\n",
    "df['col_name'].[]\n",
    "[] =[unique, value_counts, nunique]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of pieces across all unique Lego sets - drops dupes then gets sum of all pieces\n",
    "df.drop_duplicates(subset='prod_id')['piece_count'].sum() \n",
    "\n",
    "# normalized value counts - gives percentages\n",
    "df['review_difficulty'].value_counts(normalize=True)\n",
    "\n",
    "# Get the 90% quantile for all numerical columns\n",
    "df.quantile(q=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting by columns and values in pandas\n",
    "\n",
    "df.loc[df['column_name'] == some_value]\n",
    "df.loc[df['column_name'].isin(some_values)]\n",
    "df.loc[(df['column_name'] >= A) & (df['column_name'] <= B)]\n",
    "df.loc[df['column_name'] != some_value]\n",
    "df.loc[~df['column_name'].isin(some_values)]       print(df.loc[df['B'].isin(['one','three'])])\n",
    "df = df.set_index(['B'])\n",
    "print(df.loc['one'])\n",
    "\n",
    "table[table.column_name == some_value]\n",
    "table[(table.column_name == some_value) | (table.column_name2 == some_value2)]\n",
    "table.query('column_name == some_value | column_name2 == some_value2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts string to date time\n",
    "# may sometimes have to explicitly pass how the date is formatted\n",
    "pd.to_datetime(df['DATE']).head() \n",
    "pd.to_datetime(df['DATE'], format='%m/%d/%Y').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt stores all the built in datetime methods (only works for datetime columns)\n",
    "# returns what day of the week it is\n",
    "df['DATE'].dt.day_name().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Nans and Replace Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop them:\n",
    "np.isnan()\n",
    "pd.dataframename.isna()\n",
    "pd.dataframename.isnull()\n",
    "pd.notna()\n",
    "\n",
    "# replace them:\n",
    "pd.dataframename.replace(np.nan, 'replace with this')\n",
    "dataframename.fillna('replace all Nans with this')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't pass the axis=1 parameter, pandas will try and drop a row with the specified index\n",
    "df = df.drop('C/A', axis=1) \n",
    "df = df.drop(columns='C/A') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'c/a' and 'scp' columns\n",
    "df = df.drop(['c/a', 'scp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data type of the 'date' column to a date\n",
    "# Add a new column 'day_of_week' that represents the day of the week \n",
    "# Group the data by day of week and plot the sum of the numeric columns\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "df['day_of_week'] = df['date'].dt.dayofweek\n",
    "\n",
    "grouped = df.groupby('day_of_week').sum()\n",
    "grouped.plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by weekend/weekday and plot the sum of the numeric columns\n",
    "wkend = grouped.groupby('is_weekend').sum()\n",
    "wkend[['entries', 'exits']].plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups by mean number of stars for each business id\n",
    "df.groupby('business_id')['stars'].mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the keep=False to keep the duplicates and sort values to put duplicates next to each other\n",
    "df[df.duplicated(keep=False)].sort_values(by='business_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "df = df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create pivot tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This transforms the data into a person by person spreadsheet and what stars they gave various restaurants\n",
    "# Most values are NaN (null or missing) because people only review a few restaurants of those that exist\n",
    "usr_reviews = df.pivot(index='user_id', columns='business_id', values='stars')\n",
    "usr_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reformatting Column Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['ENTRIES'].dtype) # check an individual column type rather then all \n",
    "\n",
    "df['ENTRIES'] = df['ENTRIES'].astype(float) # changing the column to float/etc\n",
    "\n",
    "df['ENTRIES'] = df['ENTRIES'].astype(int) # changing the column to float/etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempting to convert a string column to int or float will produce errors if there are actually \n",
    "# non-numeric characters\n",
    "df['LINENAME'] = df['LINENAME'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming Columns (using dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'DATE' : 'date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting and Editing by Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selects based on conditional - boolean indexing\n",
    "df.loc[df['alcohol'] < 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color intensity for alcohol less than 12\n",
    "df.loc[df['alcohol'] < 12, ['color_intensity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets all color intensity greater than 10 to 10\n",
    "df.loc[df['color_intensity'] > 10, 'color_intensity'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates new column named 'shade' and fills in values of either light or dark based on color intensity\n",
    "df.loc[df['color_intensity'] > 7, 'shade'] = 'dark'\n",
    "df.loc[df['color_intensity'] <= 7, 'shade'] = 'light'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print rows 5 through 9 and columns 'Home Team Name' and 'Away Team Name'\n",
    "df.loc[5:9,['Home Team Name', 'Away Team Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all info for games played in 1950 for Group 3\n",
    "df.loc[(df[\"Year\"] == 1950) & (df[\"Stage\"] == \"Group 3\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the 'Attendance' column for games played in 1950 for Group 3\n",
    "df.loc[(df['Year'] == 1950) & (df['Stage'] == 'Group 3'), 'Attendance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of home games played by the Netherlands\n",
    "Neth_home = df[df['Home Team Name'] == ('Netherlands')]\n",
    "print(len(Neth_home))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of games played by the Netherlands in total\n",
    "Neth_away = df[df['Away Team Name']==('Netherlands')]\n",
    "print(len(Neth_home)+len(Neth_away))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of games the USA played in the 2014 world cup\n",
    "USA_home_and_away = df[(df['Year'] == 2014) &\n",
    "                       ((df['Home Team Name'] == 'USA') |\n",
    "                        (df['Away Team Name'] == 'USA'))]\n",
    "print(len(USA_home_and_away))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of countries participated in the 1986 world cup\n",
    "games_86 = df[df['Year'] == 1986]\n",
    "home = list(games_86['Home Team Name'].unique())\n",
    "away = list(games_86['Away Team Name'].unique())\n",
    "print(len(home))\n",
    "home += away\n",
    "print(len(home))\n",
    "print(len(set(home)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of matches that had more than 5 goals in total\n",
    "df['Total_Goals'] = df['Home Team Goals'] + df['Away Team Goals']\n",
    "print(len(df[df['Total_Goals'] >= 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'Half-time Goals' in df\n",
    "df['Half-time Goals'] = df['Half-time Home Goals'] + df['Half-time Away Goals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all records containing the string 'Korea'\n",
    "df.loc[df['Home Team Name'].str.contains('Korea'), 'Home Team Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the 'Home Team Name' and 'Home Team Initials' columns \n",
    "df.loc[df['Home Team Name'] == 'Korea DPR', 'Home Team Name'] = 'Korea'\n",
    "df.loc[df['Home Team Initials'] == 'KOR', 'Home Team Initials'] = 'NSK'\n",
    "\n",
    "# Check the updated columns\n",
    "df.loc[df['Home Team Name'].str.contains('Korea')]\n",
    "df.loc[df['Away Team Name'].str.contains('Korea')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting by row and column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selects the 4th row\n",
    "df.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[5:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selects rows and columns\n",
    "df.iloc[:, 3:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[5:10, 3:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns based on row and column name\n",
    "df.loc[:, 'magnesium']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[7:16, 'magnesium']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DATE'].iloc[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting a New Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the index to 'linename'\n",
    "df = df.set_index('linename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index\n",
    "df = df.reset_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Map, Apply, and Lambda Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a new column based on criteria applied through a lambda function (instead of writing a sep. function)\n",
    "df['On_N_Line'] = df['LINENAME'].map(lambda x: 'N' in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates new column based on criteria\n",
    "# map function used on a function (contains_n is a function previously defined)\n",
    "df['On_N_Line'] = df['LINENAME'].map(contains_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns percentage of each value\n",
    "df['On_N_Line'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new 'num_lines' column that has a count of each line in linename\n",
    "df['num_lines'] = df['linename'].map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the above function to clean the column names\n",
    "# clean is a previously defined function\n",
    "df.columns = [clean(col) for col in df.columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts every value in the dataframe to a string\n",
    "string_df = df.applymap(lambda x: str(x))\n",
    "string_df.info() # shows every column as string data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squares every value in the age column\n",
    "display(df['Age'].apply(lambda x: x**2).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a new column for number of words in review column\n",
    "df['Review_Word_Length'] = df['text'].map(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditional, any method, and a list comprehension all inside a lambda function\n",
    "df['text'].map(lambda x: 'Good' if any([word in x.lower() for word in \n",
    "                                        ['awesome', 'love', 'good', 'great']]) else 'Bad').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selects the year (in a datetime column)\n",
    "df.date.map(lambda x: x[:4]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by last name\n",
    "names = ['Miriam Marks','Sidney Baird','Elaine Barrera','Eddie Reeves','Marley Beard',\n",
    "         'Jaiden Liu','Bethany Martin','Stephen Rios','Audrey Mayer','Kameron Davidson']\n",
    "sorted(names, key=lambda x: x.split()[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .apply - used for columns/series\n",
    "# .applymap - used for the whole data frame / all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
